{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Denoising Auto-Encoders with TensorFlow\n",
    "--------- \n",
    "Nikolas Wolfe<br>\n",
    "11-785 Deep Learning Seminar<br>\n",
    "December 20th, 2015\n",
    "<br>\n",
    "<h2 style=\"color:red;\">Note:</h2><br>\n",
    "I used Google <a href=\"https://www.tensorflow.org/\">TensorFlow</a> for this homework. TensorFlow is a new, cutting-edge ML/Deep Learning library released in November 2015. It's claimed advantages over existing deep learning frameworks (some of which I can verify are true) are its ability to seamlessly handle the optimization of computations using an efficient back-end written in C++ and run on a CPU, GPU, or multiple distributed GPUs using the same code base. In their <a href='http://download.tensorflow.org/paper/whitepaper2015.pdf'>whitepaper</a>, Google claims the purpose of TensorFlow is to do large-scale machine learning on heterogeneous distributed systems.\n",
    "\n",
    "As promising as these claims sound, TensorFlow is definitively <em>not</em> ready for prime-time. The <a href=\"https://www.tensorflow.org/versions/master/api_docs/index.html\">API</a> is terse and incomplete, and there are few documented implementations of systems beyond the canned examples on the <a href=\"https://www.tensorflow.org/versions/master/tutorials/index.html\">website</a>. Doing this homework required building new infrastructure for not only constructing arbitrarily designed networks, e.g. a stacked denoising auto-encoder (which has already been <a href=\"https://github.com/hussius/ascii-autoencoder/blob/master/ascii_autoencoder.py\">tried</a> by some independent parties), but also reading in an <a href=\"http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html\">external</a> dataset. These are all tasks which have yet to be documented in any detail by Google, and TensorFlow is critically lacking in this respect. The documentation deals exlusively with very clean and expediently formatted datasets. \n",
    "\n",
    "In summary, I cannot claim to have gotten this homework working entirely, though the process has been spec'd out in extensive detail here and maybe in the near future someone will find a way to make this work. Rest assured that it <em>can</em> work, but the API is still too limited for something like this.\n",
    "\n",
    "<h3>TensorFlow is good for 11-785!</h3>\n",
    "\n",
    "This is not to completely disregard the potential of TensorFlow. Some of the <a href=\"https://www.tensorflow.org/versions/master/tutorials/index.html\">tutorials</a> are actually quite substantial, including examples of convolutional networks for image classification on the <a href=\"https://www.tensorflow.org/versions/master/tutorials/deep_cnn/index.html\">CIFAR-10</a> and <a href=\"https://www.tensorflow.org/versions/master/tutorials/image_recognition/index.html\">ImageNet</a> datasets, <a href=\"https://www.tensorflow.org/versions/master/tutorials/word2vec/index.html\">word2vec</a>, <a href=\"https://www.tensorflow.org/versions/master/tutorials/recurrent/index.html\">RNNs & LSTMs</a> and how to do neural network based <a href=\"https://www.tensorflow.org/versions/master/tutorials/seq2seq/index.html\">Machine Translation</a>, among other things. It is for this reason that in the future I would <em>highly</em> recommend the use of TensorFlow for the pedagogical purposes of 11-785. On the website, the above topics were <a href=\"http://deeplearning.cs.cmu.edu/labs/labs.html\">all</a> listed as things which were originally going to be made into homeworks, and thus this frameowork provides a useful foundation to get the more lay students going with deep learning. TensorFlow is likely to be well-supported into the future, it will get faster, and many observers ([<a href=\"http://www.infoworld.com/article/3003920/data-science/4-no-bull-takeaways-about-googles-machine-learning-project.html\">1</a>][<a href=\"http://www.pcmag.com/article2/0,2817,2494727,00.asp\">2</a>][<a href=\"http://www.geekwire.com/2015/google-open-sources-tensorflow-machine-learning-system-offering-its-neural-network-to-outside-developers/\">3</a>][<a href=\"http://www.wired.com/2015/11/google-open-sources-its-artificial-intelligence-engine/\">4</a>]) agree it has a fundamentally more flexibile (if not intuitive) design than Theano, Torch or Caffe, and its rough-around-the-edges bleeding-edge state arguably makes it ideal for exploration in a class like this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "Download PASCAL VOC2007 dataset from VOC2007 website. This dataset includes training, validation and testing sets. You can fnd the images inside JPEGImages folder and the labels inside the ImageSets/Main folder.\n",
    "\n",
    "I downloaded the VOC2007 dataset, and I have placed the train/test data in two folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -l train/VOC2007/\n",
    "ls -l test/VOC2007/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Together there are 2501 training images, 2510 validation images and 4952 testing images. Train a Denosing Autoencoder with different noise levels using the training set and visualize the learned filters as in here. Here you can use the whole image (re-size to a fixed size, e.g., 256x256) or sub-sampled small patches with a fixed size (e.g., 30x30). Comparing both of them will give you extra credits.\n",
    "### Image Input Types to Test:\n",
    "* 256 x 256 Resizing\n",
    "* Convolutional sub-samples (30 x 30)\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ------- TENSORFLOW --------- #\n",
    "import tensorflow as tf\n",
    "import sys, os, math, numpy\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ------------------ General ------------------- #\n",
    "IMG_DIR = 'VOC2007' + os.sep + 'JPEGImages' + os.sep\n",
    "LBL_DIR = 'VOC2007' + os.sep + 'ImageSets' + os.sep + 'Main' + os.sep\n",
    "\n",
    "# ------------------ Training ------------------ #\n",
    "TRAIN_DIR = 'train' + os.sep + IMG_DIR\n",
    "TRAIN_LABELS = 'train' + os.sep + LBL_DIR\n",
    "\n",
    "# ------------------ Testing ------------------- # \n",
    "TEST_DIR = 'test' + os.sep + IMG_DIR\n",
    "TEST_LABELS = 'test' + os.sep + LBL_DIR\n",
    "\n",
    "# ------------------ Misc ------------------- # \n",
    "NUM_CLASSES = 20\n",
    "ACTIVATION = 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(TRAIN_DIR)\n",
    "print(TRAIN_LABELS)\n",
    "print(TEST_DIR)\n",
    "print(TEST_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels for the images are stored in the 'Main' directory, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls train/VOC2007/ImageSets/Main/ | head -4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in these files are in the following form, where the 1st column corresponds to the jpeg file and the 2nd column corresponds to whether the label is present, as shown in the output below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "tail train/VOC2007/ImageSets/Main/bicycle_train.txt | head -4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to verify this, we can look at somet of these files from the 'JPEGImages' folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "x = Image(filename=TRAIN_DIR + '009926.jpg', width=256, height=256) # this IS a bicycle\n",
    "y = Image(filename=TRAIN_DIR + '009940.jpg', width=256, height=256) # this is NOT a bicycle\n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the Data\n",
    "We first need to import the dataset and get it into the appropriate data structures which are used in TensorFlow. In this case I will not separate the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generic read data from our file structure...\n",
    "def get_data(DIR, LABELS, key):\n",
    "    imgs = {}\n",
    "    labels = defaultdict(list)\n",
    "    label_list = []\n",
    "    for root, dirs, files in os.walk(LABELS, topdown=False):\n",
    "        for f in files: \n",
    "            if '_' + key in f: \n",
    "                label = f.split('_')[0] \n",
    "                label_list.append(label)\n",
    "                f = os.path.abspath(LABELS + f)\n",
    "                pos_ex = [l.split()[0] for l in open(f).readlines() if l.split()[-1] == '1']\n",
    "                for img in pos_ex:\n",
    "                    labels[label].append(img)\n",
    "                    imgs[img] = os.path.abspath(DIR + img + '.jpg')\n",
    "    return imgs, labels, label_list\n",
    "\n",
    "# Dig through for the training data...\n",
    "def get_train_data(): return get_data(TRAIN_DIR, TRAIN_LABELS, \"trainval.txt\")        \n",
    "\n",
    "# Dig through for the testing data...\n",
    "def get_test_data(): return get_data(TEST_DIR, TEST_LABELS, \"test.txt\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in train and test data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --------- TRAIN & TEST SETS --------- #\n",
    "train_imgs, train_labels, label_list = get_train_data()\n",
    "test_imgs, test_labels, label_list = get_test_data()\n",
    "print('Labels: ' + ', '.join(label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For use in classification later on, we're going to find it useful to have 20-dimensional 1-hot bit vectors to represent our 20 PASCAL classification labels. So we'll go ahead and create those representations here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_one_hot_label_list(label_dict):\n",
    "    keys = OrderedDict(sorted(label_dict.items())).keys()\n",
    "    one_hot_lookup = {}\n",
    "    for i in range(len(keys)):\n",
    "        one_hot = numpy.zeros(NUM_CLASSES)\n",
    "        one_hot[i] = 1\n",
    "        one_hot_lookup[keys[i]] = one_hot\n",
    "    one_hot_list = []\n",
    "    for label in label_dict.keys():\n",
    "        vals = label_dict[label]\n",
    "        for v in vals:\n",
    "            one_hot_list.append((v, one_hot_lookup[label]))\n",
    "    return one_hot_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a mapping between the image keys and the one-hot labels. We add a duplicate image key entry to the list if the image contains more than one label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels_one_hot = get_one_hot_label_list(train_labels)\n",
    "test_labels_one_hot = get_one_hot_label_list(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to read in the images and create TensorFlow tensors with them... In this function we will associate the one-hot dictionaries with the files their keys point to. As per the requirements of the first part of this assignment, we will also call an operation to resize the images to 256 x 256 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reads in data, creates grey-scale img...\n",
    "def read_img_data(one_hot_dict, file_dict):\n",
    "    labels = []\n",
    "    files = []\n",
    "    img_files = []\n",
    "    reader = tf.WholeFileReader()\n",
    "    print('Assembling files...')\n",
    "    for (img, label_vec) in one_hot_dict:\n",
    "        files.append(file_dict[img])\n",
    "        labels.append(label_vec)\n",
    "    queue = tf.train.string_input_producer(files)\n",
    "    jpg_key, jpg_img = reader.read(queue)\n",
    "    # grey-scale the image...\n",
    "    jpg_img = tf.image.decode_jpeg(jpg_img, channels=1)\n",
    "    init = tf.initialize_all_variables()\n",
    "    # Run session...\n",
    "    print('Starting tensorflow session...')\n",
    "    with tf.Session() as sess:\n",
    "        with tf.device('/cpu:0'):\n",
    "            sess.run(init)\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "            for i in range(len(files)):\n",
    "                jpg = jpg_img.eval()\n",
    "                jpg = numpy.asarray(jpg)\n",
    "                jpg.resize((256, 256))\n",
    "                img_files.append(jpg)\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "            \n",
    "    # build numpy arrays\n",
    "    print('Reconstructing arrays...')\n",
    "    img_files = numpy.asarray(img_files)\n",
    "    labels = numpy.asarray(labels)\n",
    "    print('Done!')\n",
    "    return img_files, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data By Class Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_train_data_for_label(label):\n",
    "    print('Getting data for ' + label + '...')\n",
    "    imgs_for_label = train_labels[label]\n",
    "    lbl_dict = {}\n",
    "    lbl_dict[label] = imgs_for_label\n",
    "    one_hot_dict = get_one_hot_label_list(lbl_dict)\n",
    "    img_files, labels = read_img_data(one_hot_dict, train_imgs)\n",
    "    print(\"Tensor shape: \" + str(numpy.shape(img_files)))\n",
    "    return img_files, labels\n",
    "    \n",
    "def get_test_data_for_label(label): \n",
    "    print('Getting data for ' + label + '...')\n",
    "    imgs_for_label = test_labels[label]\n",
    "    lbl_dict = {}\n",
    "    lbl_dict[label] = imgs_for_label\n",
    "    one_hot_dict = get_one_hot_label_list(lbl_dict)\n",
    "    img_files, labels = read_img_data(one_hot_dict, test_imgs)\n",
    "    print(\"Tensor shape: \" + str(numpy.shape(img_files)))\n",
    "    return img_files, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_files, labels = get_test_data_for_label('bird')\n",
    "img_files, labels = get_train_data_for_label('sofa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Auto-Encoders\n",
    "An auto-encoder can be defined as follows. For $k$ dimensional data, we reduce the data to a lower dimensional representation $j$ using a matrix multiplication:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\\begin{align}\n",
    "softmax\\left(W * x + b\\right) &= x^{\\prime}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Where $W$ is a matrix from $R^k \\rightarrow R^j$ and $x^{\\prime}$ is the lower dimensional representation of the input. \n",
    "\n",
    "The reconstruction function maps the matrix $W^{\\prime}$ from $R^j$ to $R^k$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "softmax\\left(W^{\\prime} * x^{\\prime} + b^{\\prime}\\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function we want to minimize overall is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "cost = || \\ softmax^{\\prime} \\left(W^{\\prime} * (softmax(W * x + b)) + b^{\\prime}\\right) - x \\ ||\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is essentially minimizing the cross-entropy of the reconstruction with the original input. And for a deep autoencoder, as in Problem 2, we simply stack successive layers of these reductions. The code below will work for both stacked and non-stacked encoders. First, we need to be able to construct an auto-encoder given a shape description..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------- #\n",
    "# Returns a weight tensor with the specified dimensions\n",
    "# ------------------------------------------------------------- #\n",
    "def get_weight_tensor(input_dim, output_dim):\n",
    "    shape = [input_dim, output_dim]\n",
    "    std = 1.0 / math.sqrt(float(input_dim))\n",
    "    rand_init_values = tf.truncated_normal(shape, stddev=std)\n",
    "    return tf.Variable(rand_init_values)\n",
    "\n",
    "# ------------------------------------------------------------- #\n",
    "# Returns a bias tensor with the specified dimension\n",
    "# ------------------------------------------------------------- #\n",
    "def get_bias_tensor(dim):\n",
    "    zero_init_values = tf.zeros([dim], tf.float32)\n",
    "    return tf.Variable(zero_init_values)\n",
    "\n",
    "# ------------------------------------------------------------- #\n",
    "# Get the weighted sum of the inputs plus the bias\n",
    "# ------------------------------------------------------------- #\n",
    "def get_mult_op(inputs, weights, bias):\n",
    "    return tf.matmul(inputs, weights) + bias\n",
    "\n",
    "# ------------------------------------------------------------- #\n",
    "# Applies the parameterized activation function to the layer\n",
    "# ------------------------------------------------------------- #\n",
    "def get_activation(layer, type='sigmoid'):\n",
    "    if type is 'sigmoid': return tf.nn.sigmoid(layer)\n",
    "    elif type is 'relu': return tf.nn.relu(layer)\n",
    "    elif type is 'softmax': return tf.nn.softmax(layer)\n",
    "    elif type is 'tanh': return tf.nn.tanh(layer)\n",
    "    elif type is 'linear': return layer\n",
    "    else: return layer\n",
    "    \n",
    "# ------------------------------------------------------------- #\n",
    "# Builds an autoencoder structure for the input vector and shape\n",
    "# ------------------------------------------------------------- #\n",
    "def build_autoencoder_for_shape(input_vector, shape):\n",
    "    # ----------------------------------------------------------- #\n",
    "    # Layer input\n",
    "    layer_input = input_vector\n",
    "    # ----------------------------------------------------------- #\n",
    "    # Weight matrices for encoder structure\n",
    "    encoder_weights = []\n",
    "    # ----------------------------------------------------------- #\n",
    "    # Build the layers based on the vector dimensions in shape...\n",
    "    # ----------------------------------------------------------- #\n",
    "    print(\"Building layer... | layer dim: \" + str(int(layer_input.get_shape()[1])))\n",
    "    for layer_dimension in shape:\n",
    "        # ------------------------------------------------------------- #\n",
    "        # Get the layer dimensions...\n",
    "        print(\"Building layer... | layer dim: \" + str(layer_dimension))\n",
    "        # ------------------------------------------------------------- #\n",
    "        # Build a weight matrix...\n",
    "        input_dimension = int(layer_input.get_shape()[1])\n",
    "        W = get_weight_tensor(input_dimension, layer_dimension)\n",
    "        # ------------------------------------------------------------- #\n",
    "        # Build a bias vector...\n",
    "        b = get_bias_tensor(layer_dimension)\n",
    "        # ------------------------------------------------------------- #\n",
    "        # Append the weight matrix to the encoder data structure...\n",
    "        encoder_weights.append(W)\n",
    "        # ------------------------------------------------------------- #\n",
    "        # Layer input multiplication\n",
    "        X = get_mult_op(layer_input, W, b)\n",
    "        # ------------------------------------------------------------- #\n",
    "        # Get the layer output computation, e.g. O = sigmoid(X)\n",
    "        O = get_activation(X, type=ACTIVATION)\n",
    "        # ------------------------------------------------------------- #\n",
    "        # Plug the output of this layer to the input of the next...\n",
    "        layer_input = O\n",
    "        \n",
    "    # ------------------------------------------------------------- #\n",
    "    # Reached the middle layer encoding of the input... \n",
    "    input_encoding = layer_input\n",
    "    \n",
    "    # ------------------------------------------------------------- #\n",
    "    # Now work your way out with symmetric structure about the middle\n",
    "    shape.reverse()\n",
    "    encoder_weights.reverse()\n",
    "    \n",
    "    # ------------------------------------------------------------- #\n",
    "    # Stacked Autoencoder layers + output dimension...\n",
    "    # Skip (reversed) shape[0] b/c that's the encoder layer!\n",
    "    shape = shape[1:] + [int(input_vector.get_shape()[1])]\n",
    "    \n",
    "    # ------------------------------------------------------------- #\n",
    "    # For tied weights, we can just use the encoder_weights[i] and\n",
    "    # transpose them!\n",
    "    for i, layer_dimension in enumerate(shape):\n",
    "        # ------------------------------------------------------------- #\n",
    "        print(\"Building layer... | layer dim: \" + str(layer_dimension))\n",
    "        # ------------------------------------------------------------- #\n",
    "        # Transpose the weight matrix...\n",
    "        W = tf.transpose(encoder_weights[i])\n",
    "        # ------------------------------------------------------------- #\n",
    "        # Bias vector...\n",
    "        b = get_bias_tensor(layer_dimension)\n",
    "        # ------------------------------------------------------------- #\n",
    "        # Input operation... Also have to transpose the input!\n",
    "        X = get_mult_op(tf.transpose(layer_input), W, b)\n",
    "        # ------------------------------------------------------------- #\n",
    "        # Activation operation, e.g. O = sigmoid(X)\n",
    "        O = get_activation(X, type=ACTIVATION)\n",
    "        # ------------------------------------------------------------- #\n",
    "        # Plug the output of this layer to the input of the next...\n",
    "        # Also have to transpose here...\n",
    "        layer_input = tf.transpose(O)\n",
    "        \n",
    "    # ------------------------------------------------------------- #\n",
    "    # Autoencoder output: Reconstruction of the input... (transpose)\n",
    "    input_reconstruction = tf.transpose(layer_input)\n",
    "    \n",
    "    # ------------------------------------------------------------- #\n",
    "    # MINIMIZE THE CROSS ENTROPY BETWEEN THE INPUT & RECONSTRUCTION\n",
    "    # ------------------------------------------------------------- #\n",
    "    cost_function = tf.sqrt(tf.reduce_mean(tf.square(input_vector - input_reconstruction)))\n",
    "    # ------------------------------------------------------------- #\n",
    "    \n",
    "    # ------------------------------------------------------------- #\n",
    "    # Return hash structure with encoder, decoder, and cost func\n",
    "    # ------------------------------------------------------------- #\n",
    "    return {\n",
    "        'encoder' : input_encoding,\n",
    "        'decoder' : input_reconstruction,\n",
    "        'cost'    : cost_function\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Single Layer Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_single_layer_autoencoder(input_dim, reduced_dim):\n",
    "    x = tf.placeholder(\"float\", [None, input_dim])\n",
    "    autoencoder = build_autoencoder_for_shape(x, [reduced_dim])\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it with TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dim = 25\n",
    "reduced_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    autoencoder = build_single_layer_autoencoder(input_dim, reduced_dim)\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll move on to <strong>Problem 2</strong> just for convenience sake now, then talk about the feature extraction...\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "Given the PASCAL dataset from Part 1, train a Stacked Denosing Autoencoder\n",
    "as in here using the training set and use it as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A fixed network to extract features. Train RBF SVMs using the extracted features from the training set. Again, here you can use a small network trained with sub-sampled inputs and average the output of the network to get image-level features when you train the SVMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A pre-trained network to initialize a feed-forward network and finne-tune the feed-forward network using the training set. Here you will have to use the whole re-sized images as the inputs. Given the fact that an image may have multiple labels in this dataset, you may not want to use a softmax layer as your output layer. Explore the network structure and SVM parameters to achieve the best validation accuracy (mAP for SVM) you can get. Report the best network structure, SVM parameters the corresponding testing MAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Example: Stacked Deep Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_stacked_autoencoder(input_dim, shape):\n",
    "    x = tf.placeholder(\"float\", [None, input_dim])\n",
    "    autoencoder = build_autoencoder_for_shape(x, shape)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it with TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 1024\n",
    "shape = [512, 256, 128, 64, 32, 16, 8, 4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    autoencoder = build_stacked_autoencoder(input_dim, shape)\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguably a bit overkill... but you get the idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running & Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an RBF-Kernel SVM Classifier\n",
    "Below is a skeleton class for training an RBF-Kernel SVM classifier. <strong>NOTE:</strong> This is largely copied from the SciLearn documentation: <a href=\"http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html#example-svm-plot-rbf-parameters-py\">Click here!</a>\n",
    "\n",
    "First, some imports from SciLearn's LibSVM wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function to move the midpoint of a colormap to be around the values of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Run SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Load and prepare data set\n",
    "#\n",
    "# dataset for grid search\n",
    "def run_rbf_svm():\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "\n",
    "    # Dataset for decision function visualization: we only keep the first two\n",
    "    # features in X and sub-sample the dataset to keep only 2 classes and\n",
    "    # make it a binary classification problem.\n",
    "\n",
    "    X_2d = X[:, :2]\n",
    "    X_2d = X_2d[y > 0]\n",
    "    y_2d = y[y > 0]\n",
    "    y_2d -= 1\n",
    "\n",
    "    # It is usually a good idea to scale the data for SVM training.\n",
    "    # We are cheating a bit in this example in scaling all of the data,\n",
    "    # instead of fitting the transformation on the training set and\n",
    "    # just applying it on the test set.\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_2d = scaler.fit_transform(X_2d)\n",
    "\n",
    "    ##############################################################################\n",
    "    # Train classifiers\n",
    "    #\n",
    "    # For an initial search, a logarithmic grid with basis\n",
    "    # 10 is often helpful. Using a basis of 2, a finer\n",
    "    # tuning can be achieved but at a much higher cost.\n",
    "\n",
    "    C_range = np.logspace(-2, 10, 13)\n",
    "    gamma_range = np.logspace(-9, 3, 13)\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "    cv = StratifiedShuffleSplit(y, n_iter=5, test_size=0.2, random_state=42)\n",
    "    grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    print(\"The best parameters are %s with a score of %0.2f\"\n",
    "          % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "    # Now we need to fit a classifier for all parameters in the 2d version\n",
    "    # (we use a smaller set of parameters here because it takes a while to train)\n",
    "\n",
    "    C_2d_range = [1e-2, 1, 1e2]\n",
    "    gamma_2d_range = [1e-1, 1, 1e1]\n",
    "    classifiers = []\n",
    "    for C in C_2d_range:\n",
    "        for gamma in gamma_2d_range:\n",
    "            clf = SVC(C=C, gamma=gamma)\n",
    "            clf.fit(X_2d, y_2d)\n",
    "            classifiers.append((C, gamma, clf))\n",
    "\n",
    "    ##############################################################################\n",
    "    # visualization\n",
    "    #\n",
    "    # draw visualization of parameter effects\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    xx, yy = np.meshgrid(np.linspace(-3, 3, 200), np.linspace(-3, 3, 200))\n",
    "    for (k, (C, gamma, clf)) in enumerate(classifiers):\n",
    "        # evaluate decision function in a grid\n",
    "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        # visualize decision function for these parameters\n",
    "        plt.subplot(len(C_2d_range), len(gamma_2d_range), k + 1)\n",
    "        plt.title(\"gamma=10^%d, C=10^%d\" % (np.log10(gamma), np.log10(C)),\n",
    "                  size='medium')\n",
    "\n",
    "        # visualize parameter's effect on decision function\n",
    "        plt.pcolormesh(xx, yy, -Z, cmap=plt.cm.RdBu)\n",
    "        plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_2d, cmap=plt.cm.RdBu_r)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.axis('tight')\n",
    "\n",
    "    # plot the scores of the grid\n",
    "    # grid_scores_ contains parameter settings and scores\n",
    "    # We extract just the scores\n",
    "    scores = [x[1] for x in grid.grid_scores_]\n",
    "    scores = np.array(scores).reshape(len(C_range), len(gamma_range))\n",
    "\n",
    "    # Draw heatmap of the validation accuracy as a function of gamma and C\n",
    "    #\n",
    "    # The score are encoded as colors with the hot colormap which varies from dark\n",
    "    # red to bright yellow. As the most interesting scores are all located in the\n",
    "    # 0.92 to 0.97 range we use a custom normalizer to set the mid-point to 0.92 so\n",
    "    # as to make it easier to visualize the small variations of score values in the\n",
    "    # interesting range while not brutally collapsing all the low score values to\n",
    "    # the same color.\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot,\n",
    "               norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "    plt.xlabel('gamma')\n",
    "    plt.ylabel('C')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "    plt.yticks(np.arange(len(C_range)), C_range)\n",
    "    plt.title('Validation accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_rbf_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
