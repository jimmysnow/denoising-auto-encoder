{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-Forward Network\n",
    "Builder & Example for a feed-forward fully-connected neural network with TensorFlow\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from read_data import DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flags\n",
    "Basic model parameters as external flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "TRAIN_DIR = 'data'\n",
    "TEST_DIR = 'data'\n",
    "MAX_EPOCHS = 2000\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input & Output Label Placeholders\n",
    "Returns two placeholders for the input/labels constructed for a given batch size... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_input_label_placeholder(input_dim):\n",
    "    input_placeholder = tf.placeholder(tf.float32, shape=(BATCH_SIZE,input_dim))\n",
    "    label_placeholder = tf.placeholder(tf.float32, shape=(BATCH_SIZE))\n",
    "    return input_placeholder, label_placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Feed Dictionary \n",
    "Constructions a feed_dict to use with the SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_feed_dict(data_set, input_placeholder, label_placeholder):\n",
    "    input_feed, label_feed = data_set.next_batch(BATCH_SIZE)\n",
    "    feed_dict = {\n",
    "        input_placeholder: input_feed,\n",
    "        label_placeholder: label_feed,\n",
    "    }\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights\n",
    "Returns a tensor with the desired shape (array) and randomly initializes weights using seed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_weight_tensor(input_dim, output_dim):\n",
    "    shape = [input_dim, output_dim]\n",
    "    std = 1.0 / math.sqrt(float(input_dim))\n",
    "    rand_init_values = tf.truncated_normal(shape, stddev=std)\n",
    "    return tf.Variable(rand_init_values, name='weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias\n",
    "Returns a tensor with the desired shape (array) and initializes with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bias_tensor(dim):\n",
    "    zero_init_values = tf.zeros(dim)\n",
    "    return tf.Variable(zero_init_values, name='biases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Input\n",
    "Returns tensorflow opearation for the multiplication of the weights * inputs + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mult_op(inputs, weights, bias):\n",
    "    return tf.matmul(inputs, weights) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "Returns a tensorflow activation function based on the name passed to the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_activation(layer, type='sigmoid'):\n",
    "    if type is 'sigmoid': return tf.nn.sigmoid(layer)\n",
    "    elif type is 'relu': return tf.nn.relu(layer)\n",
    "    elif type is 'softmax': return tf.nn.softmax(layer)\n",
    "    elif type is 'tanh': return tf.nn.tanh(layer)\n",
    "    elif type is 'linear': return layer\n",
    "    else: return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Layer\n",
    "Returns a new layer constructed from the inputs with the specified name scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_layer(name, input_vec, input_dim, output_dim, activ='sigmoid'):\n",
    "    # size of the input\n",
    "    with tf.name_scope(name):\n",
    "        # weight matrix\n",
    "        weights = get_weight_tensor(input_dim, output_dim)\n",
    "        # bias vector\n",
    "        bias = get_bias_tensor(output_dim)\n",
    "        # weighted combination of inputs\n",
    "        mult = get_mult_op(input_vec, weights, bias)\n",
    "        # activation function\n",
    "        output = get_activation(mult, activ)\n",
    "    return output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Constructor\n",
    "Given a shape and an input placeholder, builds an FF network with a specified activation and output types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_network(input_vec, shape, num_inputs, num_outputs, activ='sigmoid', out_func='sigmoid'):\n",
    "    shape = [num_inputs] + shape\n",
    "    for i in range(1, len(shape)):\n",
    "        in_dim = shape[i-1]\n",
    "        out_dim = shape[i]\n",
    "        name = 'hidden_layer' + str(i)\n",
    "        print('Constructing ' + name + '...')\n",
    "        network = build_layer(name, input_vec, in_dim, out_dim, activ)\n",
    "        input_vec = network\n",
    "    name = 'output_' + out_func\n",
    "    print('Constructing ' + name + '...')\n",
    "    network = build_layer(name, input_vec, shape[-1], num_outputs, out_func)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Loss Function\n",
    "Returns a loss function based from an output network layer and a function type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_loss_function(network_output_layer, labels, loss_func='mse'):\n",
    "    if loss_func is None or loss_func is '': loss_func = 'mse'\n",
    "    if loss_func is 'mse': \n",
    "        mse = tf.square(network_output_layer - labels)\n",
    "        loss = tf.reduce_mean(mse, name=loss_func)\n",
    "        return loss\n",
    "    elif loss_func is 'xentropy': \n",
    "        xent = tf.nn.softmax_cross_entropy_with_logits(network_output_layer, labels, name=loss_func) \n",
    "        loss = tf.reduce_mean(xent, name=loss_func)\n",
    "        return loss\n",
    "    elif loss_func is 'sig_xentropy':\n",
    "        sig_xent = tf.nn.sigmoid_cross_entropy_with_logits(network_output_layer, labels, name=loss_func)\n",
    "        loss = tf.reduce_mean(sig_xent, name=loss_func)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function\n",
    "Returns a gradient descent training optimizer from a provided loss function for a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_training_function(loss_function, learning_rate):\n",
    "    # Add a scalar summary for the snapshot loss.\n",
    "    tf.scalar_summary(loss_function.op.name, loss_function)\n",
    "    # Create the gradient descent optimizer with the given learning rate.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    # Create a variable to track the global step.\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    # Use the optimizer to apply the gradients that minimize the loss\n",
    "    # (and also increment the global step counter) as a single training step.\n",
    "    train_op = optimizer.minimize(loss_function, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Takes the label data and evaluates the accuracy of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluation(network, labels):\n",
    "    correct = tf.nn.in_top_k(network, labels, 1)\n",
    "    return tf.reduce_sum(tf.cast(correct, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_evaluation(sess, network, input_placeholder, label_placeholder, data_set):\n",
    "    # num correct\n",
    "    true_count = 0\n",
    "    steps_per_epoch = data_set.num_test_examples / BATCH_SIZE\n",
    "    num_examples = steps_per_epoch * BATCH_SIZE\n",
    "    for step in range(steps_per_epoch):\n",
    "        feed_dict = fill_feed_dict(data_set, input_placeholder, label_placeholder)\n",
    "        true_count += sess.run(network, feed_dict=feed_dict)\n",
    "    precision = true_count / num_examples\n",
    "    print('Num examples: %d  Num correct: %d  Precision @ 1: %0.04f' % (num_examples, true_count, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Shape\n",
    "Build a two-layer relu network with linear softmax output for MNIST data classification\n",
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE\n",
    "INPUT_DIMENSION = 2\n",
    "OUTPUT_DIMENSION = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_train():\n",
    "    # Load dataset\n",
    "    data_set = DataSet(TRAIN_DIR, INPUT_DIMENSION, name='diamond')\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        # Get input and output label placeholders\n",
    "        input_placeholder, label_placeholder = get_input_label_placeholder(INPUT_DIMENSION)\n",
    "        \n",
    "        # Network specification\n",
    "        net_shape = [128, 32]\n",
    "        network = construct_network(input_placeholder, net_shape, INPUT_DIMENSION, OUTPUT_DIMENSION)\n",
    "        \n",
    "        # Loss function\n",
    "        loss_function = get_loss_function(network, label_placeholder)\n",
    "        \n",
    "        # Training Function\n",
    "        train_op = get_training_function(loss_function, LEARNING_RATE)\n",
    "        \n",
    "        # Evaluation Operation\n",
    "        eval_op = get_eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nwolfe/BoxSync/Fall-2015/DeepLearning/HW2/denoising-auto-encoder/data/diamond-train.csv\n",
      "/Users/nwolfe/BoxSync/Fall-2015/DeepLearning/HW2/denoising-auto-encoder/data/diamond-test.csv\n",
      "Constructing hidden_layer1...\n",
      "Constructing hidden_layer2...\n",
      "Constructing output_sigmoid...\n"
     ]
    }
   ],
   "source": [
    "do_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
