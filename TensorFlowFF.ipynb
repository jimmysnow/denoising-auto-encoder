{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-Forward Network\n",
    "Builder & Example for a feed-forward fully-connected neural network with TensorFlow\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "import time\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from read_data import DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flags\n",
    "Basic model parameters as external flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "TRAIN_DIR = 'data'\n",
    "TEST_DIR = 'data'\n",
    "MAX_EPOCHS = 2000\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input & Output Label Placeholders\n",
    "Returns two placeholders for the input/labels constructed for a given batch size... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_input_label_placeholder(input_dim):\n",
    "    input_placeholder = tf.placeholder(tf.float32, shape=(BATCH_SIZE,input_dim))\n",
    "    label_placeholder = tf.placeholder(tf.int32, shape=(BATCH_SIZE))\n",
    "    return input_placeholder, label_placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Feed Dictionary \n",
    "Constructions a feed_dict to use with the SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_feed_dict(data_set, input_placeholder, label_placeholder, type=\"train\"):\n",
    "    input_feed, label_feed = data_set.next_batch(BATCH_SIZE, type=type)\n",
    "    feed_dict = {\n",
    "        input_placeholder: input_feed,\n",
    "        label_placeholder: label_feed,\n",
    "    }\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights\n",
    "Returns a tensor with the desired shape (array) and randomly initializes weights using seed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_weight_tensor(input_dim, output_dim):\n",
    "    shape = [input_dim, output_dim]\n",
    "    std = 1.0 / math.sqrt(float(input_dim))\n",
    "    rand_init_values = tf.truncated_normal(shape, stddev=std)\n",
    "    return tf.Variable(rand_init_values, name='weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias\n",
    "Returns a tensor with the desired shape (array) and initializes with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bias_tensor(dim):\n",
    "    zero_init_values = tf.zeros([dim], tf.float32)\n",
    "    return tf.Variable(zero_init_values, name='biases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Input\n",
    "Returns tensorflow opearation for the multiplication of the weights * inputs + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mult_op(inputs, weights, bias):\n",
    "    return tf.matmul(inputs, weights) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "Returns a tensorflow activation function based on the name passed to the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_activation(layer, type='sigmoid'):\n",
    "    if type is 'sigmoid': return tf.nn.sigmoid(layer)\n",
    "    elif type is 'relu': return tf.nn.relu(layer)\n",
    "    elif type is 'softmax': return tf.nn.softmax(layer)\n",
    "    elif type is 'tanh': return tf.nn.tanh(layer)\n",
    "    elif type is 'linear': return layer\n",
    "    else: return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Layer\n",
    "Returns a new layer constructed from the inputs with the specified name scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_layer(name, input_vec, input_dim, output_dim, activ='sigmoid'):\n",
    "    # size of the input\n",
    "    with tf.name_scope(name):\n",
    "        # weight matrix\n",
    "        weights = get_weight_tensor(input_dim, output_dim)\n",
    "        # bias vector\n",
    "        bias = get_bias_tensor(output_dim)\n",
    "        # weighted combination of inputs\n",
    "        mult = get_mult_op(input_vec, weights, bias)\n",
    "        # activation function\n",
    "        output = get_activation(mult, activ)\n",
    "    return output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Constructor\n",
    "Given a shape and an input placeholder, builds an FF network with a specified activation and output types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_network(input_vec, shape, num_inputs, num_outputs, activ='sigmoid', out_func='linear'):\n",
    "    shape = [num_inputs] + shape\n",
    "    for i in range(1, len(shape)):\n",
    "        in_dim = shape[i-1]\n",
    "        out_dim = shape[i]\n",
    "        name = 'hidden_layer' + str(i)\n",
    "        print('Constructing ' + name + '...')\n",
    "        network = build_layer(name, input_vec, in_dim, out_dim, activ)\n",
    "        input_vec = network\n",
    "    name = 'output_' + out_func\n",
    "    print('Constructing ' + name + '...')\n",
    "    network = build_layer(name, input_vec, shape[-1], num_outputs, out_func)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Loss Function\n",
    "Returns a loss function based from an output network layer and a function type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_loss_function(network_output_layer, labels, loss_func='xentropy'):\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    if loss_func is None or loss_func is '': loss_func = 'mse'\n",
    "    if loss_func is 'mse': \n",
    "        mse = tf.square(network_output_layer - labels)\n",
    "        loss = tf.reduce_mean(mse, name=loss_func)\n",
    "        return loss\n",
    "    elif loss_func is 'xentropy': \n",
    "        xent = tf.nn.softmax_cross_entropy_with_logits(network_output_layer, labels, name=loss_func) \n",
    "        loss = tf.reduce_mean(xent, name=loss_func)\n",
    "        return loss\n",
    "    elif loss_func is 'sig_xentropy':\n",
    "        sig_xent = tf.nn.sigmoid_cross_entropy_with_logits(network_output_layer, labels, name=loss_func)\n",
    "        loss = tf.reduce_mean(sig_xent, name=loss_func)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function\n",
    "Returns a gradient descent training optimizer from a provided loss function for a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_training_function(loss_function, learning_rate):\n",
    "    # Create the gradient descent optimizer with the given learning rate.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    # Create a variable to track the global step.\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=True)\n",
    "    # Use the optimizer to apply the gradients that minimize the loss\n",
    "    # (and also increment the global step counter) as a single training step.\n",
    "    train_op = optimizer.minimize(loss_function, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Takes the label data and evaluates the accuracy of the network on this set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluation(network, labels):\n",
    "    correct = tf.nn.in_top_k(network, labels, 1)\n",
    "    return tf.reduce_sum(tf.cast(correct, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_evaluation(sess, eval_op, input_placeholder, label_placeholder, data_set):\n",
    "    # num correct\n",
    "    true_count = 0\n",
    "    steps_per_epoch = int(data_set.num_test_examples / BATCH_SIZE)\n",
    "    print('steps: ' + str(steps_per_epoch))\n",
    "    num_examples = steps_per_epoch * BATCH_SIZE\n",
    "    for step in range(steps_per_epoch):\n",
    "        feed_dict = fill_feed_dict(data_set, input_placeholder, label_placeholder, type=\"train\")\n",
    "        print('size: ' + str(len(feed_dict)))\n",
    "        true_count += sess.run(eval_op, feed_dict=feed_dict)\n",
    "        print('true count: ' + str(true_count))\n",
    "    precision = true_count / num_examples\n",
    "    print('Num examples: %d  Num correct: %d  Precision @ 1: %0.04f' % (num_examples, true_count, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving & Restoring the Model\n",
    "Returns a TF object which enables us to save a checkpoint snapshot of the model while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_saver(): return tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(saver, sess, step): saver.save(sess, TRAIN_DIR, global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retore_checkpoint(saver, sess): saver.save(sess, TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Shape\n",
    "Build a two-layer relu network with linear softmax output\n",
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE\n",
    "INPUT_DIMENSION = 2\n",
    "OUTPUT_DIMENSION = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_train():\n",
    "    # Load dataset\n",
    "    data_set = DataSet(TRAIN_DIR, INPUT_DIMENSION, name='DRShape')\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "    \n",
    "        # Get input and output label placeholders\n",
    "        input_placeholder, label_placeholder = get_input_label_placeholder(INPUT_DIMENSION)\n",
    "\n",
    "        # Network Specification\n",
    "        net_shape = [128, 32]\n",
    "        network = construct_network(input_placeholder, net_shape, INPUT_DIMENSION, OUTPUT_DIMENSION)\n",
    "\n",
    "        # Loss Function\n",
    "        loss_function = get_loss_function(network, label_placeholder)\n",
    "\n",
    "        # Training Function\n",
    "        train_op = get_training_function(loss_function, LEARNING_RATE)\n",
    "\n",
    "        # Evaluation Operation\n",
    "        eval_op = evaluation(network, label_placeholder)\n",
    "\n",
    "        # Checkpoint saver...\n",
    "        saver = get_saver()\n",
    "\n",
    "        # Start & Run Session\n",
    "        with tf.Session() as sess:\n",
    "            init = tf.initialize_all_variables()\n",
    "            sess.run(init)\n",
    "            \n",
    "            # Train Loop\n",
    "            for step in range(MAX_EPOCHS):\n",
    "                start_time = time.time()\n",
    "            \n",
    "                # get a batch\n",
    "                feed_dict = fill_feed_dict(data_set, input_placeholder, label_placeholder)\n",
    "                \n",
    "                # Training operation\n",
    "                _, loss_val = sess.run([train_op, loss_function], feed_dict=feed_dict)\n",
    "                \n",
    "                duration = time.time() - start_time\n",
    "                \n",
    "                # Write the summaries and print an overview fairly often.\n",
    "                if step % 100 == 0:\n",
    "                    print('Epoch %d: | loss = %.2f (%.3f sec)' % (step, loss_val, duration))\n",
    "                \n",
    "                # Save a checkpoint and evaluate the model periodically.\n",
    "                if (step + 1) % 1000 == 0 or (step + 1) == MAX_EPOCHS:\n",
    "                    save_checkpoint(saver, sess, step)\n",
    "                    # Evaluate against the training set.\n",
    "                    print('Training Data Eval:')\n",
    "                    do_evaluation(sess, eval_op, input_placeholder, label_placeholder, data_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nwolfe/BoxSync/Fall-2015/DeepLearning/HW2/denoising-auto-encoder/data/DRShape-train.csv\n",
      "/Users/nwolfe/BoxSync/Fall-2015/DeepLearning/HW2/denoising-auto-encoder/data/DRShape-test.csv\n",
      "Constructing hidden_layer1...\n",
      "Constructing hidden_layer2...\n",
      "Constructing output_linear...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes TensorShape([Dimension(100), Dimension(1)]) and TensorShape([Dimension(100)]) must have the same rank",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bdf9e4687cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdo_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-e03539ca1a05>\u001b[0m in \u001b[0;36mdo_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Loss Function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Training Function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ca3ff6787d95>\u001b[0m in \u001b[0;36mget_loss_function\u001b[0;34m(network_output_layer, labels, loss_func)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m'xentropy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mxent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_output_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits\u001b[0;34m(logits, labels, name)\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[0;31m# _CrossEntropyGrad() in nn_grad but not here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m   cost, unused_backprop = gen_nn_ops._softmax_cross_entropy_with_logits(\n\u001b[0;32m--> 151\u001b[0;31m       logits, labels, name=name)\n\u001b[0m\u001b[1;32m    152\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36m_softmax_cross_entropy_with_logits\u001b[0;34m(features, labels, name)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \"\"\"\n\u001b[1;32m    595\u001b[0m   return _op_def_lib.apply_op(\"SoftmaxCrossEntropyWithLogits\",\n\u001b[0;32m--> 596\u001b[0;31m                               features=features, labels=labels, name=name)\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, g, name, **keywords)\u001b[0m\n\u001b[1;32m    631\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    632\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         return _Restructure(ops.convert_n_to_tensor_or_indexed_slices(outputs),\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   1711\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1415\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1416\u001b[0m                          % op.type)\n\u001b[0;32m-> 1417\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1418\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36m_SoftmaxCrossEntropyWithLogitsShape\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0mlogits_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[0mlabels_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    479\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m       \u001b[0mnew_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36massert_same_rank\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         raise ValueError(\n\u001b[0;32m--> 524\u001b[0;31m             \"Shapes %s and %s must have the same rank\" % (self, other))\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massert_has_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes TensorShape([Dimension(100), Dimension(1)]) and TensorShape([Dimension(100)]) must have the same rank"
     ]
    }
   ],
   "source": [
    "do_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
