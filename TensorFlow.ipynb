{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Using TensorFlow With GPU</h1>\n",
    "<p>Assuming you have an NVIDIA GPU with Cuda Compute Capability 3.0 or above...</p>\n",
    "<p>Build TensorFlow from <a href=\"https://www.tensorflow.org/versions/master/get_started/os_setup.html#source\">source</a> and configure it using the following command:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# cd to tensorflow root, do the following... The unofficial setting lets you use 3.0 GPUs instead of minimum 3.5\n",
    "# TF_UNOFFICIAL_SETTING=1 ./configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Note that the above has some interactive prompts you need to fill out, so you can't do it from within this notebook. Then create a pip install like this:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Make sure you're using python 2.7\n",
    "# python --version\n",
    "# download and install tensorflow with gpu capability (from the pip package you build from source!!!)\n",
    "# see: https://www.tensorflow.org/versions/master/get_started/os_setup.html#create-pip\n",
    "\n",
    "# ====================== UNCOMMENT THIS LINE ===================== #\n",
    "# pip install /tmp/tensorflow_pkg/tensorflow-0.5.0-py2-none-any.whl\n",
    "\n",
    "# Note: the name of the .whl may change in the future..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now your code will run through the damn GPU from your iPython notebook. Sick, huh? Now do this:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "CPU = \"/cpu:0\"\n",
    "GPU = \"/gpu:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Computational Graphs with TensorFlow</h2>\n",
    "<p>TensorFlow uses graphs to define computations. You create constants and operations, and using a <code>Session()</code> object, allow TesnorFlow to automatically handle the overhead of allocating resources and calling external libraries for you. When the session finishes, the resources are freed and the session terminates.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "# some constants and an operation (variables...)\n",
    "matrix1 = tf.constant([[3.,3.]]) # 1 x 2 matrix\n",
    "matrix2 = tf.constant([[2.],[2.]]) # 2 x 1 matrix\n",
    "product = tf.matmul(matrix1, matrix2) # (1 x 2) * (2 x 1)\n",
    "\n",
    "# create/run the session\n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "\n",
    "print(result)\n",
    "\n",
    "#close session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Trying the above using a <code>with</code> block...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(product)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You can also run it on a GPU or CPU by design:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n",
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "def run_on_dev(dev=\"/gpu:0\"):\n",
    "    with tf.Session() as sess:\n",
    "        with tf.device(dev):\n",
    "            A = tf.constant([[3.,3.]])\n",
    "            B = tf.constant([[2.],[2.]])\n",
    "            product = tf.matmul(A, B)\n",
    "            result = sess.run(product)\n",
    "            print(result)\n",
    "\n",
    "dev1 = CPU\n",
    "dev2 = GPU\n",
    "run_on_dev(dev1)\n",
    "run_on_dev(dev2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2. -1.]\n"
     ]
    }
   ],
   "source": [
    "# create interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.Variable([1.0, 2.0])\n",
    "a = tf.constant([3.0, 3.0])\n",
    "\n",
    "# initialize x\n",
    "x.initializer.run()\n",
    "\n",
    "# add an op to subtract a from x\n",
    "sub = tf.sub(x, a)\n",
    "print(sub.eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# floats\n",
    "# print(tf.float32)\n",
    "# print(tf.float64)\n",
    "\n",
    "# ints\n",
    "# print(tf.int64)\n",
    "# print(tf.int32)\n",
    "# print(tf.int16)\n",
    "# print(tf.int8)\n",
    "# print(tf.uint8)\n",
    "\n",
    "# other\n",
    "# print(tf.string)\n",
    "# print(tf.bool)\n",
    "# print(tf.complex64)\n",
    "\n",
    "# quantized\n",
    "# print(tf.qint32)\n",
    "# print(tf.qint8)\n",
    "# print(tf.quint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device Allocation & Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dev_log(dev):\n",
    "    with tf.device(dev):\n",
    "        a = tf.constant([1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0], shape=[9,1], name='a')\n",
    "        b = tf.constant([1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0], shape=[1,9], name='b')\n",
    "        c = tf.matmul(a, b)\n",
    "    # run\n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess: \n",
    "        print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   3.   4.   5.   6.   7.   8.   9.]\n",
      " [  2.   4.   6.   8.  10.  12.  14.  16.  18.]\n",
      " [  3.   6.   9.  12.  15.  18.  21.  24.  27.]\n",
      " [  4.   8.  12.  16.  20.  24.  28.  32.  36.]\n",
      " [  5.  10.  15.  20.  25.  30.  35.  40.  45.]\n",
      " [  6.  12.  18.  24.  30.  36.  42.  48.  54.]\n",
      " [  7.  14.  21.  28.  35.  42.  49.  56.  63.]\n",
      " [  8.  16.  24.  32.  40.  48.  56.  64.  72.]\n",
      " [  9.  18.  27.  36.  45.  54.  63.  72.  81.]]\n",
      "[[  1.   2.   3.   4.   5.   6.   7.   8.   9.]\n",
      " [  2.   4.   6.   8.  10.  12.  14.  16.  18.]\n",
      " [  3.   6.   9.  12.  15.  18.  21.  24.  27.]\n",
      " [  4.   8.  12.  16.  20.  24.  28.  32.  36.]\n",
      " [  5.  10.  15.  20.  25.  30.  35.  40.  45.]\n",
      " [  6.  12.  18.  24.  30.  36.  42.  48.  54.]\n",
      " [  7.  14.  21.  28.  35.  42.  49.  56.  63.]\n",
      " [  8.  16.  24.  32.  40.  48.  56.  64.  72.]\n",
      " [  9.  18.  27.  36.  45.  54.  63.  72.  81.]]\n"
     ]
    }
   ],
   "source": [
    "# run on CPU\n",
    "dev_log(CPU)\n",
    "\n",
    "# run on GPU\n",
    "dev_log(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def big_tensor_multiply(dev,dim=1000):\n",
    "    with tf.device(dev):\n",
    "        a = tf.constant(np.random.rand(dim,dim), shape=[dim,dim], name='a')\n",
    "        b = tf.constant(np.random.rand(dim,dim), shape=[dim,dim], name='b')\n",
    "        c = tf.matmul(a, b)\n",
    "        d = tf.matrix_inverse(c)\n",
    "    # soft_placement allows tensorflow to allocate ops to device of its choice\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "        print(sess.run(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20990674 -0.20230829  0.17776081 ..., -0.20146913  0.10701872\n",
      "  -0.00976813]\n",
      " [ 0.29962251  0.66250558 -0.87355327 ...,  0.49991114 -0.54095028\n",
      "  -0.09736525]\n",
      " [-0.78200617  0.8090682   0.42642459 ..., -0.66816305  0.90810963\n",
      "   0.53495434]\n",
      " ..., \n",
      " [ 1.40751078 -2.00168374 -0.41832389 ...,  0.78288914 -0.85603356\n",
      "  -1.32163825]\n",
      " [ 0.42822143 -0.65827047 -0.15779854 ...,  0.28139009 -0.16366303\n",
      "  -0.30078936]\n",
      " [ 0.25333576 -0.05197653  0.18205467 ..., -0.07066444  0.09918352\n",
      "   0.41477799]]\n"
     ]
    }
   ],
   "source": [
    "big_tensor_multiply(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def use_multiple_devices(devices):\n",
    "    for d in devices:\n",
    "        print(\"Using device: \" + d)\n",
    "        big_tensor_multiply(d)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: /gpu:0\n",
      "[[  1.67987110e+01   4.59042604e+00  -7.03502289e+00 ...,  -5.90590991e+00\n",
      "   -2.61779107e+01   3.09562784e+01]\n",
      " [  2.93990567e+00   8.93633654e-01  -1.23732048e+00 ...,  -1.13977535e+00\n",
      "   -4.85073875e+00   5.58757069e+00]\n",
      " [  9.93436299e+00   2.65019172e+00  -4.14363473e+00 ...,  -3.50918142e+00\n",
      "   -1.50688831e+01   1.81543764e+01]\n",
      " ..., \n",
      " [  6.40669165e+00   1.68839968e+00  -2.82182753e+00 ...,  -2.31056570e+00\n",
      "   -9.34648475e+00   1.20442782e+01]\n",
      " [  9.08421470e-01   1.51617430e-01  -2.09308943e-01 ...,  -3.96352446e-03\n",
      "   -1.90075986e+00   1.47208046e+00]\n",
      " [ -3.94115146e-01  -1.37250877e-04   8.38180684e-02 ...,   1.64958373e-01\n",
      "    4.36865552e-01  -4.86890235e-01]]\n",
      "Using device: /cpu:0\n",
      "[[  81.94335386   36.65881484 -111.14857879 ..., -144.25263076\n",
      "   -21.26620605   48.12862562]\n",
      " [  13.93349061    5.93656083  -18.65762119 ...,  -24.61643898\n",
      "    -3.57620121    7.52201247]\n",
      " [  71.14872792   32.42690571  -96.95856142 ..., -125.21547656\n",
      "   -18.57256676   42.82333074]\n",
      " ..., \n",
      " [   5.67935706    3.24915169   -8.17876503 ...,   -9.96638221\n",
      "    -1.54902736    4.36226593]\n",
      " [  -2.23746344   -1.22859098    3.15409677 ...,    4.21100188\n",
      "     0.99487044   -1.99851001]\n",
      " [ -58.58125759  -26.66877504   79.82258506 ...,  103.22272011\n",
      "    15.39214814  -35.6434152 ]]\n"
     ]
    }
   ],
   "source": [
    "use_multiple_devices([GPU,CPU])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def counter_step(step):\n",
    "    # really overblown counter\n",
    "    state = tf.Variable(0, name=\"counter\")\n",
    "    \n",
    "    # val 1\n",
    "    one = tf.constant(step)\n",
    "    \n",
    "    # val step + state\n",
    "    new_val = tf.add(state, one)\n",
    "    \n",
    "    # update assign operation\n",
    "    update = tf.assign(state, new_val)\n",
    "\n",
    "    # graph launch\n",
    "    init_operation = tf.initialize_all_variables()\n",
    "\n",
    "    # run graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_operation)\n",
    "        print(sess.run(state))\n",
    "        for _ in range(3):\n",
    "            sess.run(update)\n",
    "            print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n",
      "8\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "counter_step(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>MNIST example: Handwritten Digit Recognition</h2>\n",
    "<p>First, to download and install data for MNIST dataset. This code will be reused later as well...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import input_data # comes from the file provided in the tutorial...\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# mnist.train -- training data\n",
    "# mnist.test -- testing data\n",
    "# mnist.train.images -- training images\n",
    "# mnist.train.labels -- training labesls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what the training data looks like:\n",
      "\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "Num images: 55000\n",
      "Num labels: 55000\n"
     ]
    }
   ],
   "source": [
    "print(\"Here's what the training data looks like:\\n\")\n",
    "print(mnist.train.images)\n",
    "print(\"\\nNum images: \" + str(len(mnist.train.images)))\n",
    "print(\"Num labels: \" + str(len(mnist.train.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Parameters</h2>\n",
    "<p>In this example we will only use a single layer model...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an input vector for flattened images...\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# weight matrix 784 x 10 \n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "\n",
    "# Biases\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = output = softmax(Sum(W * x) + b)\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Entropy Output\n",
    "General Form of the Cross Entropy loss function\n",
    "\\begin{align}\n",
    "H_{y^{\\prime}}\\left(y\\right) &= -\\sum_i  \\ y^{\\prime}_i \\ log\\left(y_i\\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OP: Truth value\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# OP: Loss function\n",
    "cross_entropy = -tf.reduce_sum(t * tf.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OP: GD optimization\n",
    "learning_rate = 0.01\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OP: initialize stuff. duh.\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1000 training iterations\n",
    "def train_test(dev):\n",
    "    batch_size = 100\n",
    "    num_epochs = 10000\n",
    "\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        with tf.device(dev):\n",
    "            # Run the session\n",
    "            sess.run(init)\n",
    "            for i in range(num_epochs):\n",
    "                # periodic print out\n",
    "                if i % (num_epochs/10.0) == 0: print(\"Epoch: \" + str(i) + \"...\")\n",
    "                batch_inputs, truth_values = mnist.train.next_batch(batch_size)\n",
    "                sess.run(train_step, feed_dict={x: batch_inputs, t: truth_values})\n",
    "\n",
    "            # OP: compare truth values to predictions\n",
    "            correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "\n",
    "            # OP: calculate accuracy\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "            # RUN: print the accuracy\n",
    "            test_result = sess.run(accuracy, feed_dict={x: mnist.test.images, t: mnist.test.labels})\n",
    "            print(\"Accuracy on Test set: \" + str(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0...\n",
      "Epoch: 1000...\n",
      "Epoch: 2000...\n",
      "Epoch: 3000...\n",
      "Epoch: 4000...\n",
      "Epoch: 5000...\n",
      "Epoch: 6000...\n",
      "Epoch: 7000...\n",
      "Epoch: 8000...\n",
      "Epoch: 9000...\n",
      "Accuracy on Test set: 0.9193\n"
     ]
    }
   ],
   "source": [
    "train_test(GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Deeper Model: MNIST\n",
    "But first a recap..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input & Truth Vector\n",
    "def get_placeholders():\n",
    "    x = tf.placeholder(\"float\",shape=[None,784])\n",
    "    t = tf.placeholder(\"float\",shape=[None,10])\n",
    "    return (x, t)\n",
    "\n",
    "# Weights & Bias\n",
    "def get_model_params():\n",
    "    W = tf.Variable(tf.zeros([784,10]))\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "    return (W, b)\n",
    "\n",
    "# Softmax Layer\n",
    "def get_softmax_layer(x, W, b):\n",
    "    return tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# Cost Function\n",
    "def get_cross_entropy_function(t, y):\n",
    "    return -tf.reduce_sum(t * tf.log(y))\n",
    "\n",
    "# Training module\n",
    "def get_training_module(learning_rate, cost_function):\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "# Test the model\n",
    "def do_test_model(inputs, outputs, truth):\n",
    "    correct_prediction = tf.equal(tf.argmax(outputs,1), tf.argmax(truth,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    test_accuracy = accuracy.eval(feed_dict={inputs: mnist.test.images, truth: mnist.test.labels})\n",
    "    print(\"Test Accuracy: \" + str(test_accuracy))\n",
    "\n",
    "# Training iterations\n",
    "def do_train_model(training_algo, input_values, truth_values, batch_size, num_epochs):\n",
    "    for i in range(num_epochs):\n",
    "        if i % (num_epochs/10) == 0: print(\"Epoch \" + str(i) + \"...\")\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        training_algo.run(feed_dict={input_values: batch[0], truth_values: batch[1]})\n",
    "\n",
    "# Train/test\n",
    "def do_train_test(learning_rate, batch_size, num_epochs):\n",
    "    x, t = get_placeholders()\n",
    "    W, b = get_model_params()\n",
    "    y = get_softmax_layer(x, W, b)\n",
    "    ce = get_cross_entropy_function(t, y)\n",
    "    training_algo = get_training_module(learning_rate, ce)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        do_train_model(training_algo, x, t, batch_size, num_epochs)\n",
    "        do_test_model(x, y, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0...\n",
      "Epoch 100...\n",
      "Epoch 200...\n",
      "Epoch 300...\n",
      "Epoch 400...\n",
      "Epoch 500...\n",
      "Epoch 600...\n",
      "Epoch 700...\n",
      "Epoch 800...\n",
      "Epoch 900...\n",
      "Test Accuracy: 0.9186\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "num_epochs = 1000\n",
    "do_train_test(learning_rate, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Model\n",
    "First, some data parameters we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, t = get_placeholders()\n",
    "W, b = get_model_params()\n",
    "y = get_softmax_layer(x, W, b)\n",
    "ce = get_cross_entropy_function(t, y)\n",
    "training_algo = get_training_module(learning_rate, ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a series of functions we'll need to do convolutions, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layers\n",
    "This will create a convolution layer with 32 filters, each being a 5x5 pixel patch. The shape will therefore be [5,5,1,32] which indicates the size of our filters, the number of input channels (1), and the number of output channels (32). There is also a bias vector for each output channel, so a 32-dim vector of bias terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First convolutional layer\n",
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply this layer, we reshape it to a 4d tensor, with the 2nd and 3rd dimensions corresponding to the image width and heigh, and the final dimension to the number of color channels. (1 for greyscale). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolve x_image with the weight tensor, add bias, and apply ReLU, and finally a max pool..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
