{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Using TensorFlow With GPU</h1>\n",
    "<p>Assuming you have an NVIDIA GPU with Cuda Compute Capability 3.0 or above...</p>\n",
    "<p>Build TensorFlow from <a href=\"https://www.tensorflow.org/versions/master/get_started/os_setup.html#source\">source</a> and configure it using the following command:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# cd to tensorflow root, do the following... The unofficial setting lets you use 3.0 GPUs instead of minimum 3.5\n",
    "# TF_UNOFFICIAL_SETTING=1 ./configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Note that the above has some interactive prompts you need to fill out, so you can't do it from within this notebook. Then create a pip install like this:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 2.7.11 :: Anaconda 2.4.0 (x86_64)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Make sure you're using python 2.7\n",
    "python --version\n",
    "# download and install tensorflow with gpu capability (from the pip package you build from source!!!)\n",
    "# see: https://www.tensorflow.org/versions/master/get_started/os_setup.html#create-pip\n",
    "\n",
    "# ====================== UNCOMMENT THIS LINE ===================== #\n",
    "# pip install /tmp/tensorflow_pkg/tensorflow-0.5.0-py2-none-any.whl\n",
    "#\n",
    "# Note: the name of the .whl may change in the future...\n",
    "#\n",
    "# Or if you're doing it from another machine...\n",
    "# ====================== UNCOMMENT THIS LINE ===================== #\n",
    "# pip install tensorflow\n",
    "#\n",
    "# Or, if that doesn't work\n",
    "# ====================== UNCOMMENT THIS LINE ===================== #\n",
    "# conda install -c https://conda.anaconda.org/jjhelmus tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now your code will run through the damn GPU from your iPython notebook. Sick, huh? Now do this:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "CPU = \"/cpu:0\"\n",
    "#GPU = \"/gpu:0\"\n",
    "GPU = \"/cpu:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Computational Graphs with TensorFlow</h2>\n",
    "<p>TensorFlow uses graphs to define computations. You create constants and operations, and using a <code>Session()</code> object, allow TesnorFlow to automatically handle the overhead of allocating resources and calling external libraries for you. When the session finishes, the resources are freed and the session terminates.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "# some constants and an operation (variables...)\n",
    "matrix1 = tf.constant([[3.,3.]]) # 1 x 2 matrix\n",
    "matrix2 = tf.constant([[2.],[2.]]) # 2 x 1 matrix\n",
    "product = tf.matmul(matrix1, matrix2) # (1 x 2) * (2 x 1)\n",
    "\n",
    "# create/run the session\n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "\n",
    "print(result)\n",
    "\n",
    "#close session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Trying the above using a <code>with</code> block...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(product)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You can also run it on a GPU or CPU by design:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n",
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "def run_on_dev(dev=\"/gpu:0\"):\n",
    "    with tf.Session() as sess:\n",
    "        with tf.device(dev):\n",
    "            A = tf.constant([[3.,3.]])\n",
    "            B = tf.constant([[2.],[2.]])\n",
    "            product = tf.matmul(A, B)\n",
    "            result = sess.run(product)\n",
    "            print(result)\n",
    "\n",
    "dev1 = CPU\n",
    "dev2 = GPU\n",
    "run_on_dev(dev1)\n",
    "run_on_dev(dev2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2. -1.]\n"
     ]
    }
   ],
   "source": [
    "# create interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.Variable([1.0, 2.0])\n",
    "a = tf.constant([3.0, 3.0])\n",
    "\n",
    "# initialize x\n",
    "x.initializer.run()\n",
    "\n",
    "# add an op to subtract a from x\n",
    "sub = tf.sub(x, a)\n",
    "print(sub.eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# floats\n",
    "# print(tf.float32)\n",
    "# print(tf.float64)\n",
    "\n",
    "# ints\n",
    "# print(tf.int64)\n",
    "# print(tf.int32)\n",
    "# print(tf.int16)\n",
    "# print(tf.int8)\n",
    "# print(tf.uint8)\n",
    "\n",
    "# other\n",
    "# print(tf.string)\n",
    "# print(tf.bool)\n",
    "# print(tf.complex64)\n",
    "\n",
    "# quantized\n",
    "# print(tf.qint32)\n",
    "# print(tf.qint8)\n",
    "# print(tf.quint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device Allocation & Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dev_log(dev):\n",
    "    with tf.device(dev):\n",
    "        a = tf.constant([1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0], shape=[9,1], name='a')\n",
    "        b = tf.constant([1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0], shape=[1,9], name='b')\n",
    "        c = tf.matmul(a, b)\n",
    "    # run\n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess: \n",
    "        print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   3.   4.   5.   6.   7.   8.   9.]\n",
      " [  2.   4.   6.   8.  10.  12.  14.  16.  18.]\n",
      " [  3.   6.   9.  12.  15.  18.  21.  24.  27.]\n",
      " [  4.   8.  12.  16.  20.  24.  28.  32.  36.]\n",
      " [  5.  10.  15.  20.  25.  30.  35.  40.  45.]\n",
      " [  6.  12.  18.  24.  30.  36.  42.  48.  54.]\n",
      " [  7.  14.  21.  28.  35.  42.  49.  56.  63.]\n",
      " [  8.  16.  24.  32.  40.  48.  56.  64.  72.]\n",
      " [  9.  18.  27.  36.  45.  54.  63.  72.  81.]]\n",
      "[[  1.   2.   3.   4.   5.   6.   7.   8.   9.]\n",
      " [  2.   4.   6.   8.  10.  12.  14.  16.  18.]\n",
      " [  3.   6.   9.  12.  15.  18.  21.  24.  27.]\n",
      " [  4.   8.  12.  16.  20.  24.  28.  32.  36.]\n",
      " [  5.  10.  15.  20.  25.  30.  35.  40.  45.]\n",
      " [  6.  12.  18.  24.  30.  36.  42.  48.  54.]\n",
      " [  7.  14.  21.  28.  35.  42.  49.  56.  63.]\n",
      " [  8.  16.  24.  32.  40.  48.  56.  64.  72.]\n",
      " [  9.  18.  27.  36.  45.  54.  63.  72.  81.]]\n"
     ]
    }
   ],
   "source": [
    "# run on CPU\n",
    "dev_log(CPU)\n",
    "\n",
    "# run on GPU\n",
    "dev_log(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def big_tensor_multiply(dev,dim=1000):\n",
    "    with tf.device(dev):\n",
    "        a = tf.constant(np.random.rand(dim,dim), shape=[dim,dim], name='a')\n",
    "        b = tf.constant(np.random.rand(dim,dim), shape=[dim,dim], name='b')\n",
    "        c = tf.matmul(a, b)\n",
    "        d = tf.matrix_inverse(c)\n",
    "    # soft_placement allows tensorflow to allocate ops to device of its choice\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "        print(sess.run(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-31.38444859 -19.09501874 -46.73663672 ..., -14.53397292 -20.65020629\n",
      "    6.93230569]\n",
      " [  7.84727277   3.89965026  10.73314382 ...,   3.65827177   5.22387857\n",
      "   -1.67060043]\n",
      " [ -9.57701398  -6.02240057 -14.43602501 ...,  -4.46672842  -6.37462149\n",
      "    1.9046587 ]\n",
      " ..., \n",
      " [-28.75823057 -17.74147636 -42.75766215 ..., -13.07948493 -19.36042455\n",
      "    6.28890704]\n",
      " [ 10.00818264   6.44302041  15.06993653 ...,   4.56704431   6.73123929\n",
      "   -2.06101705]\n",
      " [ -0.77141348  -1.3193186   -2.10344004 ...,  -0.3360398   -0.23916448\n",
      "   -0.07641594]]\n"
     ]
    }
   ],
   "source": [
    "big_tensor_multiply(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def use_multiple_devices(devices):\n",
    "    for d in devices:\n",
    "        print(\"Using device: \" + d)\n",
    "        big_tensor_multiply(d)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: /cpu:0\n",
      "[[ 0.07679646 -0.27353408 -0.12751289 ...,  0.0856424  -1.13138416\n",
      "  -0.03328873]\n",
      " [ 0.36858419 -0.36931438  1.14990034 ...,  0.37799874  0.68649865\n",
      "  -0.27673902]\n",
      " [ 0.61033404  0.20069893  0.57896095 ..., -0.14516779  0.60370352\n",
      "  -0.29194378]\n",
      " ..., \n",
      " [-0.24836041  0.05711571  0.41464966 ...,  0.08327197  0.64584404\n",
      "   0.41700414]\n",
      " [-0.52815259 -0.64138573 -1.29735189 ...,  0.34245771 -2.52806726\n",
      "  -0.10744348]\n",
      " [-0.74631385 -0.46004439 -0.67331659 ...,  0.25574346 -1.25555572\n",
      "  -0.01976877]]\n",
      "Using device: /cpu:0\n",
      "[[ 0.01552621 -0.46725361 -0.04231887 ..., -0.06590554  0.16044502\n",
      "  -0.14831765]\n",
      " [-0.21978828  0.52453695 -1.41511505 ...,  0.45818407  0.57338101\n",
      "  -0.80137229]\n",
      " [ 0.18339134 -0.10927796  1.02021297 ..., -0.28026921 -0.5857836\n",
      "   0.60276394]\n",
      " ..., \n",
      " [-0.11368047  0.39952238 -0.34046508 ...,  0.20978883  0.05225077\n",
      "  -0.11854756]\n",
      " [ 0.12902199 -0.58843207  0.97268844 ..., -0.46493589 -0.40401439\n",
      "   0.54104254]\n",
      " [ 0.21079995 -0.1828678   0.56807836 ..., -0.14876684 -0.37432594\n",
      "   0.41390979]]\n"
     ]
    }
   ],
   "source": [
    "use_multiple_devices([GPU,CPU])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def counter_step(step):\n",
    "    # really overblown counter\n",
    "    state = tf.Variable(0, name=\"counter\")\n",
    "    \n",
    "    # val 1\n",
    "    one = tf.constant(step)\n",
    "    \n",
    "    # val step + state\n",
    "    new_val = tf.add(state, one)\n",
    "    \n",
    "    # update assign operation\n",
    "    update = tf.assign(state, new_val)\n",
    "\n",
    "    # graph launch\n",
    "    init_operation = tf.initialize_all_variables()\n",
    "\n",
    "    # run graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_operation)\n",
    "        print(sess.run(state))\n",
    "        for _ in range(3):\n",
    "            sess.run(update)\n",
    "            print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n",
      "8\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "counter_step(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([ 0.16752651], dtype=float32), array([ 0.36398095], dtype=float32))\n",
      "(20, array([ 0.10501249], dtype=float32), array([ 0.29727489], dtype=float32))\n",
      "(40, array([ 0.10099418], dtype=float32), array([ 0.29945952], dtype=float32))\n",
      "(60, array([ 0.10019718], dtype=float32), array([ 0.29989281], dtype=float32))\n",
      "(80, array([ 0.1000391], dtype=float32), array([ 0.29997876], dtype=float32))\n",
      "(100, array([ 0.10000775], dtype=float32), array([ 0.29999581], dtype=float32))\n",
      "(120, array([ 0.10000155], dtype=float32), array([ 0.29999918], dtype=float32))\n",
      "(140, array([ 0.10000031], dtype=float32), array([ 0.29999983], dtype=float32))\n",
      "(160, array([ 0.10000009], dtype=float32), array([ 0.29999995], dtype=float32))\n",
      "(180, array([ 0.10000009], dtype=float32), array([ 0.29999995], dtype=float32))\n",
      "(200, array([ 0.10000009], dtype=float32), array([ 0.29999995], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "x_data = np.random.rand(100).astype(\"float32\")\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# Weights\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "# Bias\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# Layer function\n",
    "y = W * x_data + b\n",
    "\n",
    "# MSE\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "\n",
    "# SGD\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# initialize variables...\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(GPU):\n",
    "        sess.run(init)\n",
    "        for step in xrange(201):\n",
    "            sess.run(train)\n",
    "            if step % 20 == 0:\n",
    "                print(step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>MNIST example: Handwritten Digit Recognition</h2>\n",
    "<p>First, to download and install data for MNIST dataset. This code will be reused later as well...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import input_data # comes from the file provided in the tutorial...\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# mnist.train -- training data\n",
    "# mnist.test -- testing data\n",
    "# mnist.train.images -- training images\n",
    "# mnist.train.labels -- training labesls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what the training data looks like:\n",
      "\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "Num images: 55000\n",
      "Num labels: 55000\n"
     ]
    }
   ],
   "source": [
    "print(\"Here's what the training data looks like:\\n\")\n",
    "print(mnist.train.images)\n",
    "print(\"\\nNum images: \" + str(len(mnist.train.images)))\n",
    "print(\"Num labels: \" + str(len(mnist.train.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Parameters</h2>\n",
    "<p>In this example we will only use a single layer model...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an input vector for flattened images...\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# weight matrix 784 x 10 \n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "\n",
    "# Biases\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = output = softmax(Sum(W * x) + b)\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Entropy Output\n",
    "General Form of the Cross Entropy loss function\n",
    "\\begin{align}\n",
    "H_{y^{\\prime}}\\left(y\\right) &= -\\sum_i  \\ y^{\\prime}_i \\ log\\left(y_i\\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OP: Truth value\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# OP: Loss function\n",
    "cross_entropy = -tf.reduce_sum(t * tf.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OP: GD optimization\n",
    "learning_rate = 0.01\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OP: initialize stuff. duh.\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1000 training iterations\n",
    "def train_test(dev):\n",
    "    batch_size = 100\n",
    "    num_epochs = 1000\n",
    "\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        with tf.device(dev):\n",
    "            # Run the session\n",
    "            sess.run(init)\n",
    "            for i in range(num_epochs):\n",
    "                # periodic print out\n",
    "                if i % (num_epochs/10.0) == 0: print(\"Epoch: \" + str(i) + \"...\")\n",
    "                batch_inputs, truth_values = mnist.train.next_batch(batch_size)\n",
    "                sess.run(train_step, feed_dict={x: batch_inputs, t: truth_values})\n",
    "\n",
    "            # OP: compare truth values to predictions\n",
    "            correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "\n",
    "            # OP: calculate accuracy\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "            # RUN: print the accuracy\n",
    "            test_result = sess.run(accuracy, feed_dict={x: mnist.test.images, t: mnist.test.labels})\n",
    "            print(\"Accuracy on Test set: \" + str(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0...\n",
      "Epoch: 100...\n",
      "Epoch: 200...\n",
      "Epoch: 300...\n",
      "Epoch: 400...\n",
      "Epoch: 500...\n",
      "Epoch: 600...\n",
      "Epoch: 700...\n",
      "Epoch: 800...\n",
      "Epoch: 900...\n",
      "Accuracy on Test set: 0.9151\n"
     ]
    }
   ],
   "source": [
    "train_test(GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Deeper Model: MNIST\n",
    "But first a recap..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input & Truth Vector\n",
    "def get_placeholders():\n",
    "    x = tf.placeholder(\"float\",shape=[None,784])\n",
    "    t = tf.placeholder(\"float\",shape=[None,10])\n",
    "    return (x, t)\n",
    "\n",
    "# Weights & Bias\n",
    "def get_model_params():\n",
    "    W = tf.Variable(tf.zeros([784,10]))\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "    return (W, b)\n",
    "\n",
    "# Softmax Layer\n",
    "def get_softmax_layer(x, W, b):\n",
    "    return tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# Cost Function\n",
    "def get_cross_entropy_function(t, y):\n",
    "    return -tf.reduce_sum(t * tf.log(y))\n",
    "\n",
    "# Training module\n",
    "def get_training_module(learning_rate, cost_function):\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "# Test the model\n",
    "def do_test_model(inputs, outputs, truth):\n",
    "    correct_prediction = tf.equal(tf.argmax(outputs,1), tf.argmax(truth,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    test_accuracy = accuracy.eval(feed_dict={inputs: mnist.test.images, truth: mnist.test.labels})\n",
    "    print(\"Test Accuracy: \" + str(test_accuracy))\n",
    "\n",
    "# Training iterations\n",
    "def do_train_model(training_algo, input_values, truth_values, batch_size, num_epochs):\n",
    "    for i in range(num_epochs):\n",
    "        if i % (num_epochs/10) == 0: print(\"Epoch \" + str(i) + \"...\")\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        training_algo.run(feed_dict={input_values: batch[0], truth_values: batch[1]})\n",
    "\n",
    "# Train/test\n",
    "def do_train_test(learning_rate, batch_size, num_epochs):\n",
    "    x, t = get_placeholders()\n",
    "    W, b = get_model_params()\n",
    "    y = get_softmax_layer(x, W, b)\n",
    "    ce = get_cross_entropy_function(t, y)\n",
    "    training_algo = get_training_module(learning_rate, ce)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        do_train_model(training_algo, x, t, batch_size, num_epochs)\n",
    "        do_test_model(x, y, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0...\n",
      "Epoch 100...\n",
      "Epoch 200...\n",
      "Epoch 300...\n",
      "Epoch 400...\n",
      "Epoch 500...\n",
      "Epoch 600...\n",
      "Epoch 700...\n",
      "Epoch 800...\n",
      "Epoch 900...\n",
      "Test Accuracy: 0.9118\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "num_epochs = 1000\n",
    "do_train_test(learning_rate, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Model\n",
    "Parameters and placeholders..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# Inputs and truth placeholder\n",
    "x, t = get_placeholders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions we'll need to do convolutions, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Convolutional Layer\n",
    "This will create a convolution layer with 32 filters, each being a 5x5 pixel patch. The shape will therefore be [5,5,1,32] which indicates the size of our filters, the number of input channels (1), and the number of output channels (32). There is also a bias vector for each output channel, so a 32-dim vector of bias terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply this layer, we reshape it to a 4d tensor, with the 2nd and 3rd dimensions corresponding to the image width and heigh, and the final dimension to the number of color channels. (1 for greyscale). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolve x_image with the weight tensor, add bias, and apply ReLU, and finally a max pool..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Second Convolutional Layer\n",
    "64 features for each 5x5 patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weight & Bias\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "# ReLU activation function & Max-pooling layer\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densly Connected Layer\n",
    "Now that the image size has been reduced to 7x7, we add a fully-connected layer with 1024 neurons to allow processing on the entire image. We reshape the tensor from the pooling layer into a batch of vectors, multiply by a weight matrix, add a bias, and apply a ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "# pooling layer\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readout Layer\n",
    "Finally, we add a softmax layer, just like for the one layer softmax regression above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = get_softmax_layer(h_fc1_drop, W_fc2, b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross Entropy loss function\n",
    "ce = get_cross_entropy_function(t, y_conv)\n",
    "\n",
    "# Function to optimize\n",
    "training_algo = tf.train.AdamOptimizer(1e-4).minimize(ce)\n",
    "\n",
    "# Correct Prediction\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(t, 1))\n",
    "\n",
    "# Accuracy calculation\n",
    "accuracy_calc = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the Training...\n",
    "def run_convolutional_mnist_model(training_algo, accuracy_calc, batch_size):\n",
    "    config=tf.ConfigProto(allow_soft_placement=True)\n",
    "    #config.gpu_options.allocator_type = 'BFC'\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        for i in range(2000):\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            if i % 100 == 0:\n",
    "                train_accuracy = accuracy_calc.eval(feed_dict={x:batch[0], t:batch[1], keep_prob:1.0})\n",
    "                print(\"Epoch: %d, Training Accuracy: %g\" % (i, train_accuracy))\n",
    "            training_algo.run(feed_dict={x:batch[0], t:batch[1], keep_prob:0.5})\n",
    "            \n",
    "        test_acc = 0\n",
    "        #test_acc = accuracy_calc.eval(feed_dict={x:mnist.test.images, t:mnist.test.labels, keep_prob:1.0})\n",
    "        #print(\"Test Accuracy: %g\" % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Accuracy: 0.13\n",
      "Epoch: 100, Training Accuracy: 0.88\n",
      "Epoch: 200, Training Accuracy: 0.92"
     ]
    }
   ],
   "source": [
    "run_convolutional_mnist_model(training_algo, accuracy_calc, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git Update Shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "git add .\n",
    "git pull\n",
    "git commit -m \"autocommit message\"\n",
    "git push -u origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
